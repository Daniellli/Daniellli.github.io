<!DOCTYPE html>
<html>

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>
    Shaocong Xu
  </title>
  <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

  <!-- Open Graph -->


  <!-- Bootstrap & MDB -->
  <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg=="
    crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css"
    integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q=="
    crossorigin="anonymous" />

  <!-- Fonts & Icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"
    integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog=="
    crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css"
    integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg=="
    crossorigin="anonymous">
  <link rel="stylesheet" type="text/css"
    href="https://fonts.useso.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

  <!-- Code Syntax Highlighting -->
  <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes/github.css">

  <!-- Styles -->

  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/">


  <!-- Dark Mode -->
  <script src="/assets/js/theme.js"></script>
  <script src="/assets/js/dark_mode.js"></script>



</head>

<body class="fixed-top-nav ">

  <!-- Header -->

  <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
      <div class="container">

        <!-- Social Icons -->
        <div class="navbar-brand social">
          <a href="mailto:xushaocong@stu.xmu.edu.cn"><i class="fas fa-envelope"></i></a>
          <!-- modified by shaocong xu -->
          <!-- <a href="https://scholar.google.com/citations?user=lTBMax0AAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> -->
          <a href="https://github.com/Daniellli" title="GitHub" target="_blank" rel="noopener noreferrer"><i
              class="fab fa-github"></i></a>
        </div>

        <!-- Navbar Toggle -->
        <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav"
          aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar top-bar"></span>
          <span class="icon-bar middle-bar"></span>
          <span class="icon-bar bottom-bar"></span>
        </button>
        <div class="collapse navbar-collapse text-right" id="navbarNav">
          <ul class="navbar-nav ml-auto flex-nowrap">
            <!-- About -->
            <li class="nav-item active">
              <a class="nav-link" href="/">
                about
                <span class="sr-only">(current)</span>
              </a>
            </li>
            <!-- Other pages -->
            <div class="toggle-container">
              <a id="light-toggle">
                <i class="fas fa-moon"></i>
                <i class="fas fa-sun"></i>
              </a>
            </div>
          </ul>
        </div>
      </div>
    </nav>
  </header>


  <!-- Content -->

  <div class="container mt-5">
    <div class="post">

      <header class="post-header">
        <h1 class="post-title">
          Shaocong Xu
        </h1>
        <p class="desc">Xiamen University</p>
      </header>
      <article>
        <div class="profile float-right">
          <img class="img-fluid z-depth-1 rounded" src="/assets/resized/prof_pic-480x659.png"
            srcset="    /assets/resized/prof_pic-480x659.png 480w,/assets/img/prof_pic.png 648w">
        </div>
        <div class="clearfix">

          <!-- <p>I am an assistant professor in 
        <a href="https://en.wikipedia.org/wiki/Zhejiang_University" target="_blank" rel="noopener noreferrer">Zhejiang University</a>. 
        Before that, I was a Postdoc in <a href="http://cvlibs.net/" target="_blank" rel="noopener noreferrer">Autonomous Vision Group</a>, 
        a part of the University of Tübingen and the MPI for Intelligent Systems,
         working with <a href="https://avg.is.tuebingen.mpg.de/person/ageiger" target="_blank" rel="noopener noreferrer">Prof. Andreas Geiger</a>. 
         I received my Ph.D. in Control Science and Engineering from 
         <a href="https://en.wikipedia.org/wiki/Zhejiang_University" target="_blank" rel="noopener noreferrer">Zhejiang University</a> 
         in June 2018 and the B.S. degree from 
         <a href="https://en.wikipedia.org/wiki/Xiamen_University" target="_blank" rel="noopener noreferrer">Xiamen University</a> in 2013.</p> -->
          <p>
            I am currently pursuing a master's degree in Computer Science at
            <a href="https://en.wikipedia.org/wiki/Xiamen_University" target="_blank" rel="noopener noreferrer">Xiamen
              University</a> (2021-present), being guided by
            Prof. <a href="https://www.humanplus.xyz/team" target="_blank" rel="noopener noreferrer">Shihui Guo</a>.


            Additionally, I am also serving as a visiting student at the DISCOVER lab, <a
              href="https://en.wikipedia.org/wiki/Tsinghua_University" target="_blank"
              rel="noopener noreferrer">Tsinghua University</a>,
            under the guidance of Prof. <a href="https://sites.google.com/view/fromandto" target="_blank"
              rel="noopener noreferrer">Hao Zhao</a>.

            I received my B.S. degree from <a href="https://en.wikipedia.org/wiki/Xiamen_University_of_Technology"
              target="_blank" rel="noopener noreferrer">Xiamen Univesity of Technology</a> in 2021.



          </p>
          <p>My research interests are primarily focused on the field of 3D computer vision, with a particular emphasis
            on areas such as scene perception,
            unsupervised learning, semi-supervised learning, and language-guided scene perception.
          </p>

          <p><strong style="color: green; background-color: #ffff42">Announcement</strong>: I am actively looking for
            <strong>Ph.D in 2024Fall! </strong></p>

          <!-- feel free to contact me via <a href="mailto:yiyi.liao@zju.edu.cn">email</a> -->


        </div>

        <!--!=========================news block ======================-->
        <div class="news">
          <h2>news</h2>
          <div class="table-responsive">
            <table class="table table-sm table-borderless" style="width: 100%">
              <colgroup>
                <col span="1" style="width: 15%;">
                <col span="1" style="width: 85%;">
              </colgroup>
              <!-- Put <thead>, <tbody>, and <tr>'s here! -->
              <tbody>
                <tr>
                  <th scope="row">Sept, 2023</th>
                  <td>
                    Our tutorial paper,  <a href="https://aclanthology.org/2023.ccl-4.4/" target="_blank" rel="noopener noreferrer">Foundation Models for Robotics: Best Known Practices</a>, is available.
                  </td>
                </tr>

                <tr>
                  <th scope="row">Jul, 2023</th>
                  <td>
                    Our work <a href="https://int2.cn/" target="_blank" rel="noopener noreferrer">INT2</a> is accepted
                    to ICCV2023.
                  </td>
                </tr>


                <tr>
                  <th scope="row">Jun, 2023</th>
                  <td>
                    We secure the second place in the <a href="https://scene-understanding.com/challenge.html" target="_blank" rel="noopener noreferrer">CVPR 2023 Situation Understanding Challenge</a>. 
                    Our technical report, <a href="assets/pdf/SQA_tech_report.pdf" target="_blank" rel="noopener noreferrer">SLiP: Situated-oriented Localization in Point Clouds</a>, is now available.
                  </td>
                </tr>
                
                

                <!-- <tr>
                  <th scope="row">Jun 24, 2021</th>
                  <td>
                    Our work <a href="https://github.com/fabiotosi92/SMD-Nets" target="_blank"
                      rel="noopener noreferrer">SMD-Nets</a> was featured on the <a
                      href="https://www.rsipvision.com/CVPR2021-Wednesday/6/" target="_blank"
                      rel="noopener noreferrer">CVPR Daily</a> and the <a
                      href="https://www.rsipvision.com/ComputerVisionNews-2021July/30/" target="_blank"
                      rel="noopener noreferrer">BEST OF CVPR of Computer Vision News</a>.
                  </td>
                </tr> -->

              </tbody>
              <!--
      <tr>
        <td class="date"></td>
      <td class="announcement">
        <a class="all-news" href="https://yiyiliao.github.io/news/">All older news items</a>
      </td>
      </tr>
      -->
            </table>
          </div>

        </div>
        <!--!=========================================================-->

        <!--!=========================Accomplish­ments ======================-->
        <div class="news">
          <h2>accomplish­ments</h2>
          <div class="table-responsive">
            <table class="table table-sm table-borderless" style="width: 100%">
              <colgroup>
                <col span="1" style="width: 15%;">
                <col span="1" style="width: 85%;">
              </colgroup>
              <!-- Put <thead>, <tbody>, and <tr>'s here! -->
              <tbody>

                <tr>
                  <th scope="row">June 21, 2021</th>
                  <td>
                    I was honored to receive the prestigious National First Class Scholarship, which is bestowed upon
                    the top 2% of university students.
                  </td>
                </tr>

                <!-- <tr>
                    <th scope="row">Jun 24, 2021</th>
                    <td>
                      Our work <a href="https://github.com/fabiotosi92/SMD-Nets" target="_blank"
                        rel="noopener noreferrer">SMD-Nets</a> was featured on the <a
                        href="https://www.rsipvision.com/CVPR2021-Wednesday/6/" target="_blank"
                        rel="noopener noreferrer">CVPR Daily</a> and the <a
                        href="https://www.rsipvision.com/ComputerVisionNews-2021July/30/" target="_blank"
                        rel="noopener noreferrer">BEST OF CVPR of Computer Vision News</a>.
                    </td>
                  </tr> -->

              </tbody>
              <!--
        <tr>
          <td class="date"></td>
        <td class="announcement">
          <a class="all-news" href="https://yiyiliao.github.io/news/">All older news items</a>
        </td>
        </tr>
        -->
            </table>
          </div>

        </div>
        <!--!=========================================================-->




        <div class="publications">
          <h2>selected publications</h2>
          <p> Full publication list can be found on
            <!-- <a href="https://scholar.google.com/citations?user=lTBMax0AAAAJ&amp;hl" target="_blank" rel="noopener noreferrer">Google Scholar</a>. -->
            <!-- <br> -->
            <sup>*</sup>equal contribution; <sup>♯</sup>corresponding author.
          </p>
          <h2 class="year">2023</h2>
          <ol class="bibliography">
            <!-- <li>
              <div class="row">
                <div class="col-md-3">
                  <div class="img-fluid rounded">
                    <img src="/assets/teaser/pad_teaser.png"
                      alt="Learning Point-wise Abstaining Penalty for Point Cloud Anomaly Detection" style="width: 100%;">
                  </div>

                </div>

                <div id="Schwarz2020NEURIPT" class="col-md-9">
                  
                  <div class="title">Learning Point-wise Abstaining Penalty for Point Cloud Anomaly Detection</div>
                    

                  <div class="author">
                    <strong><u><em>Shaocong Xu</em></u></strong>,
                    <a href="https://scholar.google.com/citations?user=hmii_L8AAAAJ&hl=zh-CN&oi=sra" target="_blank"
                      rel="noopener noreferrer">Pengfei Li</a>,
                    <a href="#" target="_blank"rel="noopener noreferrer">Xinyu Liu</a>,
                    <a href="#" target="_blank"rel="noopener noreferrer">Qianpu Sun</a>,
                    <a href="#" target="_blank"rel="noopener noreferrer">Yang Li</a>,
                    <a href="https://www.humanplus.xyz/team" target="_blank"rel="noopener noreferrer">Shihui Guo</a>,
                    <a href="#" target="_blank"rel="noopener noreferrer">Zhen Wang</a>,
                    <a href="https://ieeexplore.ieee.org/author/37088230717" target="_blank"rel="noopener noreferrer">Bo Jiang</a>,
                    <a href="#" target="_blank"rel="noopener noreferrer">Rui Wang</a>,
                    <a href="#" target="_blank"rel="noopener noreferrer">Kehua Sheng</a>,
                    <a href="#" target="_blank"rel="noopener noreferrer">Bo Zhang</a>,
                    and <a href="https://sites.google.com/view/fromandto" target="_blank" rel="noopener noreferrer">Hao
                      Zhao</a>
                  </div>
                  <div class="periodical">
                    <em>Under Review</em>
                    2023
                  </div>
                  <div class="links">

                    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>


                    <a href="https://github.com/Daniellli/PAD" class="btn btn-sm z-depth-0" role="button"
                      target="_blank" rel="noopener noreferrer">Code</a>

                  
                      <a href="https://www.youtube.com/watch?v=nvLgVpTZhu8" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video Demo</a> 
                      
                  </div>
                  
                  <div class="abstract hidden">
                    <p>
                      LiDAR-based semantic scene understanding is an important
                      module in the modern autonomous driving perception stack.
                      However, identifying Out-Of-Distribution points in a
                      LiDAR point cloud is challenging as point clouds lack semantically rich features when compared with RGB images. We
                      revisit this problem from the perspective of selective classification, which introduces a selective function into the standard
                      closed-set classification setup. Our solution is built upon the
                      basic idea of abstaining from choosing any known categories
                      but learns a point-wise abstaining penalty with a marginbased loss. Synthesizing outliers to approximate unlimited
                      OOD samples is also critical to this idea, so we propose a
                      strong synthesis pipeline that generates outliers originated
                      from various factors: unrealistic object categories, sampling
                      patterns and sizes. We demonstrate that learning different abstaining penalties, apart from point-wise penalty, for different
                      types of (synthesized) outliers can further improve the performance. We benchmark our method on SemanticKITTI and
                      nuScenes and achieve state-of-the-art results. Risk-coverage
                      analysis further reveals intrinsic properties of different methods. Codes and models will be publicly available.
                    </p>
                  </div>
                </div>
              </div>
            </li> -->

            <li>
              <div class="row">
                <div class="col-md-3">
                  <div class="img-fluid rounded">
                    <img src="/assets/teaser/ect_teaser.png"
                      alt="ECT: Fine-grained Edge Detection with Learned Cause Tokens" style="width: 100%;">
                  </div>

                </div>

                <div id="Schwarz2020NEURIPT" class="col-md-9">
                  <div class="title">ECT: Fine-grained Edge Detection with Learned Cause Tokens</div>

                  <div class="author">
                    <strong><u><em>Shaocong Xu</em></u></strong>,
                    <a href="https://github.com/cxx226/cxx226.github.io/blob/master/about.md" target="_blank"
                      rel="noopener noreferrer">
                      Xiaoxue Chen
                    </a>,
                    <a href="#" target="_blank" rel="noopener noreferrer">Yuhang Zheng</a>,
                    <a href="https://air.tsinghua.edu.cn/info/1046/1199.htm" target="_blank"
                      rel="noopener noreferrer">Guyue Zhou</a>,
                    <a href="https://www.intel.com/content/www/us/en/research/researchers/yurong-chen.html"
                      target="_blank" rel="noopener noreferrer">Yurong Chen</a>,
                    <a href="https://www.cis.pku.edu.cn/info/1177/1379.htm" target="_blank"
                      rel="noopener noreferrer">Hongbin Zha</a>,
                    and <a href="https://sites.google.com/view/fromandto" target="_blank" rel="noopener noreferrer">Hao
                      Zhao</a>
                  </div>
                  <div class="periodical">
                    <!-- <em>In Advances in Neural Information Processing Systems (NeurIPS)</em> -->
                    <em>Arxiv</em>
                    2023
                  </div>
                  <div class="links">
                    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>

                    <a href="https://arxiv.org/pdf/2308.03092.pdf" class="btn btn-sm z-depth-0" role="button"
                      target="_blank" rel="noopener noreferrer">PDF</a>

                    <!-- <a href="http://www.cvlibs.net/publications/Schwarz2020NEURIPS_supplementary.pdf"
                      class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Supp</a> -->

                    <!-- <a href="https://autonomousvision.github.io/graf/" class="btn btn-sm z-depth-0" role="button"
                      target="_blank" rel="noopener noreferrer">Blog</a> -->

                    <a href="https://github.com/Daniellli/ECT.git" class="btn btn-sm z-depth-0" role="button"
                      target="_blank" rel="noopener noreferrer">Code</a>

                    <!-- <a href="http://www.cvlibs.net/publications/Schwarz2020NEURIPS_poster.pdf"
                      class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Poster</a> -->

                    <!-- <a href="https://www.bilibili.com/video/BV1Lz4y1W7rN/?vd_source=3dbee2c7b78b0a77ef3b8f9b2ac6c209"
                      class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video Demo</a> -->
                      <a href="https://www.youtube.com/watch?v=MdtK8SKo0nc" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video Demo</a>
                      
                  </div>
                  <!-- Hidden abstract block -->
                  <div class="abstract hidden">
                    <p>
                      In this study, we tackle the challenging fine-grained edge detection task, which refers to
                      predicting specific edges caused by reflectance,
                      illumination, normal, and depth changes, respectively. Prior methods exploit multi-scale
                      convolutional networks,
                      which are limited in three aspects: (1) Convolutions are local operators while identifying the
                      cause of edge formation requires looking at far away pixels.
                      (2) Priors specific to edge cause are fixed in prediction heads.
                      (3) Using separate networks for generic and fine-grained edge detection, and the constraint
                      between them may be violated.
                      To address these three issues, we propose a two-stage transformer-based network sequentially
                      predicting generic edges and fine-grained edges,
                      which has a global receptive field thanks to the attention mechanism. The prior knowledge of edge
                      causes is formulated as four learnable cause tokens in
                      a cause-aware decoder design. Furthermore, to encourage the consistency between generic edges and
                      fine-grained edges,
                      an edge aggregation and alignment loss is exploited. We evaluate our method on the public
                      benchmark BSDS-RIND and several newly derived benchmarks,
                      and achieve new state-of-the-art results.
                    </p>
                  </div>
                  <!-- Hidden bibtex block -->
                </div>
              </div>
            </li>

            <li>
              <div class="row">
                <div class="col-md-3">
                  <div class="img-fluid rounded">
                    
                    <img src="/assets/teaser/int2_teaser.png"
                      alt="INT2: Interactive Trajectory Prediction at Intersections" style="width: 100%;">
                  </div>

                </div>

                <div id="Schwarz2020NEURIPT" class="col-md-9">
                  <div class="title">INT2: Interactive Trajectory Prediction at Intersections</div>

                  <div class="author">
                    <a href="#" target="_blank" rel="noopener noreferrer">Zhijie Yan</a>,
                    <a href="https://scholar.google.com/citations?user=hmii_L8AAAAJ&hl=zh-CN&oi=sra" target="_blank"
                      rel="noopener noreferrer">Pengfei Li</a>,
                    <a href="#" target="_blank" rel="noopener noreferrer">Zheng Fu</a>,
                    <strong><u><em>Shaocong Xu</em></u></strong>,
                    <a href="#" target="_blank" rel="noopener noreferrer">Yongliang Shi</a>,
                    <a href="https://github.com/cxx226/cxx226.github.io/blob/master/about.md" target="_blank"
                      rel="noopener noreferrer">Xiaoxue Chen</a>,
                    <a href="#" target="_blank" rel="noopener noreferrer">Yuhang Zheng</a>,
                    <a href="#" target="_blank" rel="noopener noreferrer">Yang Li</a>,
                    <a href="https://scholar.google.com/citations?user=NAt3vgcAAAAJ&hl=zh-CN&oi=sra" target="_blank"
                      rel="noopener noreferrer">Tianyu Liu</a>,

                    <a href="#" target="_blank" rel="noopener noreferrer">Chuxuan Li</a>,
                    <a href="#" target="_blank" rel="noopener noreferrer">Nairui Luo</a>,
                    <a href="#" target="_blank" rel="noopener noreferrer">Xu Gao</a>,
                    <a href="https://air.tsinghua.edu.cn/en/info/1046/1621.htm" target="_blank"
                      rel="noopener noreferrer">Yilun Chen</a>,

                    <a href="http://wangzuoxu.cn/" target="_blank" rel="noopener noreferrer">Zuoxu Wang</a>,
                    <a href="https://scholar.google.com/citations?user=KlHuj2QAAAAJ&hl=zh-CN&oi=ao" target="_blank"
                      rel="noopener noreferrer">Yifeng Shi </a>,
                    <a href="#" target="_blank" rel="noopener noreferrer">Pengfei Huang</a>,
                    <a href="#" target="_blank" rel="noopener noreferrer">Zhengxiao Han</a>,
                    <a href="#" target="_blank" rel="noopener noreferrer">Jirui Yuan</a>,
                    <a href="https://scholar.google.com/citations?user=AktmI14AAAAJ&hl=zh-CN&oi=ao" target="_blank"
                      rel="noopener noreferrer">Jiangtao Gong</a>,
                    <a href="https://air.tsinghua.edu.cn/info/1046/1199.htm" target="_blank"
                      rel="noopener noreferrer">Guyue Zhou</a>,
                    <a href="https://hangzhaomit.github.io/" target="_blank" rel="noopener noreferrer">Hang Zhao</a> and
                    <a href="https://sites.google.com/view/fromandto" target="_blank" rel="noopener noreferrer">Hao
                      Zhao</a>
                  </div>
                  <div class="periodical">
                    <em>In Proc. of the IEEE International Conf. on Computer Vision (ICCV)</em>
                    2023
                  </div>
                  <div class="links">
                    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>

                    <a href="#" class="btn btn-sm z-depth-0" role="button" target="_blank"
                      rel="noopener noreferrer">PDF</a>
                    <!-- <a href="http://www.cvlibs.net/publications/Schwarz2020NEURIPS_supplementary.pdf"
                      class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Supp</a> -->

                    <a href="https://github.com/AIR-DISCOVER/INT2.git" class="btn btn-sm z-depth-0" role="button"
                      target="_blank" rel="noopener noreferrer">Code</a>
                    <a href="https://int2.cn/" class="btn btn-sm z-depth-0" role="button" target="_blank"
                      rel="noopener noreferrer">Project Page</a>
                    <a href="https://int2.cn/download" class="btn btn-sm z-depth-0" role="button" target="_blank"
                      rel="noopener noreferrer">Dataset</a>
                      <a href="https://www.youtube.com/watch?v=KNkuakDvgVc" class="btn btn-sm z-depth-0" role="button" target="_blank"
                      rel="noopener noreferrer">Video Demo</a>
                  </div>
                  <!-- Hidden abstract block -->
                  <div class="abstract hidden">
                    <p>
                      Motion forecasting is an important component in autonomous driving systems.
                      One of the most challenging problems in motion forecasting is interactive trajectory prediction,
                      whose goal is to jointly forecasts the future trajectories of interacting agents.
                      To this end, we present a large-scale interactive trajectory prediction dataset named INT2 for
                      INTeractive trajectory prediction at INTersections.
                      INT2 includes 612,000 scenes, each lasting 1 minute, containing up to 10,200 hours of data. The
                      agent trajectories are auto-labeled by a high-performance offline temporal detection and fusion
                      algorithm,
                      whose quality is further inspected by human judges. Vectorized semantic maps and traffic light
                      information are also provided. Additionally, the dataset poses an interesting domain mismatch
                      challenge.
                      For each intersection, we treat rush-hour and non-rush-hour segments as different domains.
                      We benchmark the best open-sourced interactive trajectory prediction method on INT2 and Waymo Open
                      Motion, under in-domain and cross-domain settings. The dataset, code and models will be made
                      public.
                    </p>
                  </div>
                  <!-- Hidden bibtex block -->
                </div>
              </div>
            </li>
          </ol>
        </div>
      </article>
    </div>
  </div>

  <!-- Footer -->






  <footer class="fixed-bottom">
    <div class="container mt-0">
      © Copyright 2023 Shaocong Xu.
      Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a
        href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme.
      Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.
      Last updated: December 07, 2022.
    </div>
  </footer>



</body>

<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"
  integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg=="
  crossorigin="anonymous"></script>

<!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js"
  integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A=="
  crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"
  integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ=="
  crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js"
  integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw=="
  crossorigin="anonymous"></script>


<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>





<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js"
  integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script"
  src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>








</html>